# Gap statistics
set.seed(123)
gap_stat_pca <- clusGap(vehicles_pca, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat_pca) + geom_vline(xintercept = gap_stat_pca$bestK, linetype = "dashed")
best_k_gap_stat_pca <- gap_stat_pca$bestK
# Silhouette method
silhouette_scores_pca <- sapply(2:10, function(k) {
set.seed(123)
cluster_result_pca <- kmeans(vehicles_pca, centers = k)
silhouette_avg_width_pca <- mean(silhouette(cluster_result_pca$cluster, dist(vehicles_pca))[, "sil_width"])
return(silhouette_avg_width_pca)
})
best_k_silhouette_pca <- which.max(silhouette_scores_pca)
# Silhouette method
silhouette_scores_pca <- sapply(2:10, function(k) {
set.seed(123)
cluster_result_pca <- kmeans(vehicles_pca, centers = k)
silhouette_avg_width_pca <- mean(silhouette(cluster_result_pca$cluster, dist(vehicles_pca))[, "sil_width"])
return(silhouette_avg_width_pca)
})
plot(2:10, silhouette_scores_pca, type = "b", xlab = "Number of clusters", ylab = "Average silhouette width", main = "Silhouette method")
best_k_silhouette_pca <- which.max(silhouette_scores_pca)
chosen_k_pca <- max(best_k_nbclust_pca, best_k_gap_stat_pca, best_k_silhouette_pca) # Adjust as needed
set.seed(123)
kmeans_result_pca <- kmeans(vehicles_pca, centers = chosen_k_pca)
# Display k-means output, including centers, clustered results, and BSS/TSS ratio
kmeans_result_pca
BSS_pca <- kmeans_result_pca$betweenss / kmeans_result_pca$totss
WSS_pca <- kmeans_result_pca$tot.withinss
#Provide the silhouette plot and average silhouette width score for the new k-means attempt:
sil_pca <- silhouette(kmeans_result_pca$cluster, dist(vehicles_pca))
fviz_silhouette(sil_pca)
avg_sil_width_pca <- mean(sil_pca[, "sil_width"])
# Calculate Calinski-Harabasz Index
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
# Calculate Calinski-Harabasz Index
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
# Calculate Calinski-Harabasz Index
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
ch_index <- ((n - k) / (k - 1)) * (BSS / WSS)
return(ch_index)
}
ch_index_pca <- calinski_harabasz_pca(kmeans_result_pca, vehicles_pca)
ch_index_pca
ch_index_pca
# Load necessary libraries
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load dataset
vehicles <- read_excel("vehicles.xlsx")
# Pre-processing: Scaling and outlier detection/removal
# Scale the data
vehicles_scaled <- scale(vehicles[, 1:18])
# Outlier detection and removal
outliers <- apply(vehicles_scaled, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
# Remove outliers
vehicles_no_outliers <- vehicles_scaled[!apply(outliers, 1, any),]
# Determine the number of cluster centers
# NbClust
nbclust_result <- NbClust(vehicles_no_outliers, min.nc = 2, max.nc = 10, method = "kmeans")
best_k_nbclust <- nbclust_result$Best.nc[1]
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_no_outliers, kmeans, method = "wss") + geom_vline(xintercept = best_k_nbclust, linetype = "dashed")
# Gap statistics
set.seed(123)
gap_stat <- clusGap(vehicles_no_outliers, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat) + geom_vline(xintercept = gap_stat$bestK, linetype = "dashed")
best_k_gap_stat <- gap_stat$bestK
# Silhouette method
silhouette_scores <- sapply(2:10, function(k) {
set.seed(123)
cluster_result <- kmeans(vehicles_no_outliers, centers = k)
silhouette_avg_width <- mean(silhouette(cluster_result$cluster, dist(vehicles_no_outliers))[, "sil_width"])
return(silhouette_avg_width)
})
best_k_silhouette <- which.max(silhouette_scores)
# Perform k-means clustering with the chosen k value
chosen_k <- max(best_k_nbclust, best_k_gap_stat, best_k_silhouette) # You can use another method to select the final k
set.seed(123)
kmeans_result <- kmeans(vehicles_no_outliers, centers = chosen_k)
# Evaluate the clustering results using silhouette plots
sil <- silhouette(kmeans_result$cluster, dist(vehicles_no_outliers))
fviz_silhouette(sil)
avg_sil_width <- mean(sil[, "sil_width"])
#SubTask 2
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 1:18) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,1:18], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,1:18], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# Perform PCA
pca_result <- prcomp(scaled_vehicles, scale = TRUE)
# Display eigenvalues, eigenvectors, and cumulative score
summary(pca_result)
# Choose PCs with a cumulative score > 92%
cumulative_score <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
selected_pcs <- which(cumulative_score >= 0.92)[1]
# Create a new transformed dataset with selected PCs
vehicles_pca <- pca_result$x[, 1:selected_pcs]
# NbClust
nbclust_result_pca <- NbClust(vehicles_pca, min.nc = 2, max.nc = 10, method = "kmeans")
best_k_nbclust_pca <- nbclust_result_pca$Best.nc[1]
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = "wss") + geom_vline(xintercept = best_k_nbclust_pca, linetype = "dashed")
# Gap statistics
set.seed(123)
gap_stat_pca <- clusGap(vehicles_pca, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat_pca) + geom_vline(xintercept = gap_stat_pca$bestK, linetype = "dashed")
best_k_gap_stat_pca <- gap_stat_pca$bestK
# Silhouette method
silhouette_scores_pca <- sapply(2:10, function(k) {
set.seed(123)
cluster_result_pca <- kmeans(vehicles_pca, centers = k)
silhouette_avg_width_pca <- mean(silhouette(cluster_result_pca$cluster, dist(vehicles_pca))[, "sil_width"])
return(silhouette_avg_width_pca)
})
plot(2:10, silhouette_scores_pca, type = "b", xlab = "Number of clusters", ylab = "Average silhouette width", main = "Silhouette method")
best_k_silhouette_pca <- which.max(silhouette_scores_pca)
#Perform k-means clustering with the most favored k from the automated methods:
chosen_k_pca <- max(best_k_nbclust_pca, best_k_gap_stat_pca, best_k_silhouette_pca) # Adjust as needed
set.seed(123)
kmeans_result_pca <- kmeans(vehicles_pca, centers = chosen_k_pca)
# Display k-means output, including centers, clustered results, and BSS/TSS ratio
kmeans_result_pca
BSS_pca <- kmeans_result_pca$betweenss / kmeans_result_pca$totss
WSS_pca <- kmeans_result_pca$tot.withinss
# Provide the silhouette plot and average silhouette width score for the new k-means attempt:
sil_pca <- silhouette(kmeans_result_pca$cluster, dist(vehicles_pca))
fviz_silhouette(sil_pca)
avg_sil_width_pca <- mean(sil_pca[, "sil_width"])
# Calculate Calinski-Harabasz Index
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
ch_index <- ((n - k) / (k - 1)) * (BSS / WSS)
return(ch_index)
}
ch_index_pca <- calinski_harabasz_pca(kmeans_result_pca, vehicles_pca)
ch_index_pca
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
ch_index <- ((n - k) / (k - 1)) * (BSS / WSS)
return(ch_index)
}
ch_index_pca <- calinski_harabasz_pca(kmeans_result_pca, vehicles_pca)
ch_index_pca
# Plot the clusters
fviz_cluster(kmeans_fit, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
#Subtask 1
library(readxl)
library(cluster)
library(NbClust)
library(factoextra)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 2:19) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,2:19], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# NBclust
nb <- NbClust(scaled_vehicles, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
# Elbow method
fviz_nbclust(scaled_vehicles, kmeans, method = "wss")
# Gap statistics method
gap_stat <- clusGap(scaled_vehicles, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
# Silhouette method
fviz_nbclust(scaled_vehicles, kmeans, method = 'silhouette')
# Perform k-means clustering for k=2
k <- 2 # Set the most favored "k" based on the automated methods
kmeans_fit <- kmeans(scaled_vehicles, centers = k, nstart = 25)
# Print the k-means output
print(kmeans_fit)
# Plot the clusters
fviz_cluster(kmeans_fit, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Plot the clusters
fviz_cluster(kmeans_fit, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the BSS and WSS indices
BSS <- sum(kmeans_fit$size * apply(kmeans_fit$centers, 1, function(x) sum((x - mean(scaled_vehicles))^2)))
TSS <- sum(apply(scaled_vehicles, 2, function(x) sum((x - mean(scaled_vehicles))^2)))
WSS <- TSS - BSS
# Print the BSS, WSS, and BSS/TSS ratio
cat("BSS:", BSS, "\n")
cat("WSS:", WSS, "\n")
cat("BSS/TSS Ratio:", BSS/TSS, "\n")
# Calculate the BSS and WSS and TSS indices
wss <- sum(kmeans_fit$withinss)
bss <- betweenss(scaled_data, kmeans_fit$cluster)
# Calculate the BSS and WSS and TSS indices
wss <- sum(kmeans_fit$withinss)
bss <- betweenss(scaled_vehicles, kmeans_fit$cluster)
cat("WSS:", wss, "\n")
tss <- sum(dist(scaled_vehicles)^2)/nrow(scaled_data)
tss <- sum(dist(scaled_vehicles)^2)/nrow(scaled_vehicles)
# Perform k-means clustering for k=3
k <- 3 # Set the most favored "k" based on the automated methods
kmeans_fit <- kmeans(scaled_vehicles, centers = k, nstart = 25)
# Print the k-means output
print(kmeans_fit)
# Plot the clusters
fviz_cluster(kmeans_fit, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the BSS and WSS indices
BSS <- sum(kmeans_fit$size * apply(kmeans_fit$centers, 1, function(x) sum((x - mean(scaled_vehicles))^2)))
TSS <- sum(apply(scaled_vehicles, 2, function(x) sum((x - mean(scaled_vehicles))^2)))
WSS <- TSS - BSS
# Print the BSS, WSS, and BSS/TSS ratio
cat("BSS:", BSS, "\n")
cat("WSS:", WSS, "\n")
cat("BSS/TSS Ratio:", BSS/TSS, "\n")
# Create a silhouette plot
sil <- silhouette(kmeans_fit$cluster, dist(scaled_vehicles))
fviz_silhouette(sil)
# Calculate the average silhouette width score
avg_sil_width <- mean(sil[,3])
# Print the average silhouette width score
cat("Average Silhouette Width Score:", avg_sil_width, "\n")
#SubTask 2
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 2:19) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,2:19], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# Perform PCA
pca_result <- prcomp(scaled_vehicles, scale = TRUE)
summary(pca_result)
# Choose PCs with a cumulative score > 92%
cumulative_score <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
selected_pcs <- which(cumulative_score >= 0.92)[1]
# Create a new transformed dataset with selected PCs
vehicles_pca <- pca_result$x[, 1:selected_pcs]
# NbClust
nbclust_result_pca <- NbClust(vehicles_pca, min.nc = 2, max.nc = 10, method = "kmeans")
best_k_nbclust_pca <- nbclust_result_pca$Best.nc[1]
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = "wss") + geom_vline(xintercept = best_k_nbclust_pca, linetype = "dashed")
# Gap statistics
set.seed(123)
gap_stat_pca <- clusGap(vehicles_pca, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat_pca) + geom_vline(xintercept = gap_stat_pca$bestK, linetype = "dashed")
best_k_gap_stat_pca <- gap_stat_pca$bestK
# Silhouette method
silhouette_scores_pca <- sapply(2:10, function(k) {
set.seed(123)
cluster_result_pca <- kmeans(vehicles_pca, centers = k)
silhouette_avg_width_pca <- mean(silhouette(cluster_result_pca$cluster, dist(vehicles_pca))[, "sil_width"])
return(silhouette_avg_width_pca)
})
plot(2:10, silhouette_scores_pca, type = "b", xlab = "Number of clusters", ylab = "Average silhouette width", main = "Silhouette method")
best_k_silhouette_pca <- which.max(silhouette_scores_pca)
chosen_k_pca <- max(best_k_nbclust_pca, best_k_gap_stat_pca, best_k_silhouette_pca)
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
library(FactoMineR)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 2:19) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,2:19], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# Perform PCA on the scaled dataset
pca_result <- PCA(scaled_vehicles, graph = FALSE)
# Print eigenvalues and eigenvectors
print(pca_result$eig)
# Print cumulative score per principal component
print(pca_result$eig[1:10, "cumul"])
print(pca_result$eig[2:10, "cumul"])
print(pca_result$eig[1:10, "cumul"])
vehicles <- read_excel("vehicles.xlsx")
#SubTask 2
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
View(vehicles)
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,2:19], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
View(scaled_vehicles)
# Perform PCA
pca_result <- prcomp(scaled_vehicles, center = TRUE, scale = TRUE)
# Choose PCs with a cumulative score > 92%
cumulative_score <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
selected_pcs <- which(cumulative_score >= 0.92)[1]
# Create a new transformed dataset with selected PCs
vehicles_pca <- predict(pca_result, newdata = scaled_vehicles)[,1:num_PCs]
vehicles_pca <- predict(pca_result, newdata = scaled_vehicles)[,1:selected_pcs]
# NbClust
nbclust_result_pca <- NbClust(vehicles_pca, min.nc = 2,
# NbClust
nbclust_result_pca <- NbClust(vehicles_pca, min.nc = 2, max.nc = 10, method = "kmeans")
# NbClust
nbclust_result_pca <- NbClust(vehicles_pca, min.nc = 2, max.nc = 10, method = "kmeans")
best_k_nbclust_pca <- nbclust_result_pca$Best.nc[1]
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = "wss") + geom_vline(xintercept = best_k_nbclust_pca, linetype = "dashed")
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = "wss"))
# Elbow method
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = "wss")
# Gap statistics
set.seed(123)
gap_stat_pca <- clusGap(vehicles_pca, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat_pca) + geom_vline(xintercept = gap_stat_pca$bestK, linetype = "dashed")
best_k_gap_stat_pca <- gap_stat_pca$bestK
# Gap statistics
set.seed(123)
fviz_nbclust(vehicles_pca, kmeans, method = 'gap_stat')
# Silhouette method
silhouette_scores_pca <- sapply(2:10, function(k) {
set.seed(123)
cluster_result_pca <- kmeans(vehicles_pca, centers = k)
silhouette_avg_width_pca <- mean(silhouette(cluster_result_pca$cluster, dist(vehicles_pca))[, "sil_width"])
return(silhouette_avg_width_pca)
})
plot(2:10, silhouette_scores_pca, type = "b", xlab = "Number of clusters", ylab = "Average silhouette width", main = "Silhouette method")
best_k_silhouette_pca <- which.max(silhouette_scores_pca)
chosen_k_pca <- max(best_k_nbclust_pca, best_k_gap_stat_pca, best_k_silhouette_pca)
k <- 3
set.seed(123)
kmeans_result_pca <- kmeans(vehicles_pca, centers = k)
k <- 3
set.seed(123)
kmeans_result_pca <- kmeans(vehicles_pca, centers = k)
# Display k-means output, including centers, clustered results, and BSS/TSS ratio
kmeans_result_pca
WSS_pca <- sum(kmeans_result_pca$tot.withinss)
TSS_pca <- sum(kmeans_result_pca$totss)
BSS_pca <- TSS_pca - WSS_pca
BSS_ratio <- BSS_pca / TSS_pca
# Print the BSS, WSS, and the ratio of BSS over TSS
cat("BSS:", BSS, "\n")
cat("BSS:", BSS_pca, "\n")
cat("WSS:", WSS_pca, "\n")
cat("Ratio of BSS over TSS:", BSS_ratio, "\n")
# Plot the clusters
fviz_cluster(k, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Plot the clusters
fviz_cluster(kmeans_result_pca, data = scaled_vehicles, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Provide the silhouette plot and average silhouette width score for the new k-means attempt:
sil_pca <- silhouette(kmeans_result_pca$cluster, dist(vehicles_pca))
fviz_silhouette(sil_pca)
avg_sil_width_pca <- mean(sil_pca[, "sil_width"])
cat("Average Silhouette Width Score:", avg_sil_width_pca, "\n")
# Calculate Calinski-Harabasz Index
calinski_harabasz_pca <- function(cluster_result, data) {
k <- length(unique(cluster_result$cluster))
n <- nrow(data)
BSS <- cluster_result$betweenss
WSS <- cluster_result$tot.withinss
ch_index <- ((n - k) / (k - 1)) * (BSS / WSS)
return(ch_index)
}
ch_index_pca <- calinski_harabasz_pca(kmeans_result_pca, vehicles_pca)
ch_index_pca
#SubTask 2
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 2:19) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
vehicles <- apply(vehicles, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
# Outlier detection/removal using the Z-score method
outlier <- apply(vehicles, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
outliers <- apply(vehicles, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
outliers <- apply(vehicles, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# Outlier detection/removal using the Z-score method
outliers <- apply(vehicles, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
return(x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR))
})
all_numeric <- sapply(vehicles_scaled, is.numeric)
all_numeric <- sapply(scaled_vehicles, is.numeric)
library(readxl)
library(NbClust)
library(factoextra)
library(cluster)
library(ggplot2)
# Load the dataset
vehicles <- read_excel("vehicles.xlsx")
# Visualize outliers using boxplots for each variable separately
par(mfrow=c(3,6)) # Set the layout of the plots
for (i in 2:19) {
boxplot(vehicles[,i], main=paste(colnames(vehicles)[i]))
}
# Outlier detection/removal using the Z-score method
z_scores <- apply(vehicles[,2:19], 2, function(x) abs(scale(x)))
vehicles <- vehicles[rowSums(z_scores < 3) == ncol(z_scores),]
# Scaling using Min-Max scaling
scaled_vehicles <- apply(vehicles[,2:19], 2, function(x) (x - min(x)) / (max(x) - min(x)))
# Perform PCA
pca_result <- prcomp(scaled_vehicles, center = TRUE, scale = TRUE)
# Display eigenvalues, eigenvectors, and cumulative score
summary(pca_result)
# Choose PCs with a cumulative score > 92%
cumulative_score <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
selected_pcs <- which(cumulative_score >= 0.92)[1]
# Create a new transformed dataset with selected PCs
vehicles_pca <- predict(pca_result, newdata = scaled_vehicles)[,1:selected_pcs]
View(pca_result)
